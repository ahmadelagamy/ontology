{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ahmed El Agamy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\compat.py:36: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  hasattr(torch, \"has_mps\")\n",
      "c:\\Users\\Ahmed El Agamy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\thinc\\compat.py:37: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  and torch.has_mps  # type: ignore[attr-defined]\n",
      "c:\\Users\\Ahmed El Agamy\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\util.py:910: UserWarning: [W095] Model 'en_core_web_sm' (3.5.0) was trained with spaCy v3.5.0 and may not be 100% compatible with the current version (3.7.2). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology Table:\n",
      "[{'text': 'CEO', 'type': 'Potential Entity', 'relation': '', 'attributes': []}, {'text': 'Apple', 'type': 'Entity', 'relation': '', 'attributes': []}, {'text': 'Tim', 'type': 'Entity', 'relation': '', 'attributes': []}, {'text': 'Cook', 'type': 'Entity', 'relation': '', 'attributes': []}, {'text': 'product', 'type': 'Potential Entity', 'relation': '', 'attributes': []}, {'text': 'launch', 'type': 'Potential Entity', 'relation': '', 'attributes': []}]\n",
      "\n",
      "NER Table:\n",
      "[{'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': 'Apple', 'type': 'ORG'}, {'text': '', 'type': ''}, {'text': 'Tim', 'type': 'PERSON'}, {'text': 'Cook', 'type': 'PERSON'}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}]\n",
      "\n",
      "Dependency Parsing Table:\n",
      "[{'word': 'The', 'pos': 'DET', 'dependency': 'det', 'head': 'CEO'}, {'word': 'CEO', 'pos': 'NOUN', 'dependency': 'nsubj', 'head': 'announced'}, {'word': 'of', 'pos': 'ADP', 'dependency': 'prep', 'head': 'CEO'}, {'word': 'Apple', 'pos': 'PROPN', 'dependency': 'pobj', 'head': 'of'}, {'word': ',', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'CEO'}, {'word': 'Tim', 'pos': 'PROPN', 'dependency': 'compound', 'head': 'Cook'}, {'word': 'Cook', 'pos': 'PROPN', 'dependency': 'appos', 'head': 'CEO'}, {'word': ',', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'CEO'}, {'word': 'announced', 'pos': 'VERB', 'dependency': 'ROOT', 'head': 'announced'}, {'word': 'a', 'pos': 'DET', 'dependency': 'det', 'head': 'launch'}, {'word': 'new', 'pos': 'ADJ', 'dependency': 'amod', 'head': 'launch'}, {'word': 'product', 'pos': 'NOUN', 'dependency': 'compound', 'head': 'launch'}, {'word': 'launch', 'pos': 'NOUN', 'dependency': 'dobj', 'head': 'announced'}, {'word': '.', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'announced'}]\n"
     ]
    }
   ],
   "source": [
    "# imports \n",
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "  \"\"\"\n",
    "  Analyzes a sentence and outputs ontology, NER, and dependency parsing data.\n",
    "\n",
    "  Args:\n",
    "      sentence (str): The sentence to be analyzed.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary containing the ontology, NER, and dependency parsing results.\n",
    "  \"\"\"\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  # Prepare empty results dictionary\n",
    "  results = {\n",
    "      \"ontology\": [],\n",
    "      \"ner\": [],\n",
    "      \"dependency_parsing\": []\n",
    "  }\n",
    "\n",
    "  # Process each token\n",
    "  for token in doc:\n",
    "    # Extract basic information\n",
    "    text = token.text\n",
    "    pos = token.pos_\n",
    "    dep_ = token.dep_\n",
    "    head = token.head.text\n",
    "\n",
    "    # Named Entity Recognition (NER)\n",
    "    entity_text = \"\"\n",
    "    entity_type = \"\"\n",
    "    if token.ent_type_:\n",
    "      entity_text = text\n",
    "      entity_type = token.ent_type_\n",
    "    results[\"ner\"].append({\"text\": entity_text, \"type\": entity_type})\n",
    "\n",
    "    # Ontology Table (basic implementation using POS)\n",
    "    if pos in [\"NOUN\", \"PROPN\"]:  # Check for nouns and proper nouns (potential entities)\n",
    "      relation = \"\"  # Placeholder for relation (more complex logic needed)\n",
    "      attributes = []  # Placeholder for attributes (more complex logic needed)\n",
    "      results[\"ontology\"].append({\n",
    "          \"text\": text,\n",
    "          \"type\": \"Entity\" if entity_type else \"Potential Entity\",\n",
    "          \"relation\": relation,\n",
    "          \"attributes\": attributes\n",
    "      })\n",
    "\n",
    "    # Dependency Parsing\n",
    "    results[\"dependency_parsing\"].append({\n",
    "        \"word\": text,\n",
    "        \"pos\": pos,\n",
    "        \"dependency\": dep_,\n",
    "        \"head\": head\n",
    "    })\n",
    "\n",
    "  return results\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The CEO of Apple, Tim Cook, announced a new product launch.\"\n",
    "analysis_result = analyze_sentence(sentence)\n",
    "\n",
    "# Print the results (further processing might be needed)\n",
    "print(\"Ontology Table:\")\n",
    "print(analysis_result[\"ontology\"])\n",
    "print(\"\\nNER Table:\")\n",
    "print(analysis_result[\"ner\"])\n",
    "print(\"\\nDependency Parsing Table:\")\n",
    "print(analysis_result[\"dependency_parsing\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology Table:\n",
      "[{'text': '', 'type': 'Potential Entity', 'relation': '', 'attributes': ['of']}, {'text': 'Apple', 'type': 'Entity', 'relation': '', 'attributes': [], 'hypernyms': [Synset('edible_fruit.n.01'), Synset('pome.n.01')], 'synonyms': ['apple', 'apple', 'orchard_apple_tree', 'Malus_pumila']}, {'text': 'Tim', 'type': 'Entity', 'relation': '', 'attributes': []}, {'text': 'Cook', 'type': 'Entity', 'relation': '', 'attributes': [], 'hypernyms': [Synset('skilled_worker.n.01')], 'synonyms': ['cook', 'Cook', 'James_Cook', 'Captain_Cook', 'Captain_James_Cook', 'cook', 'cook', 'fix', 'ready', 'make', 'prepare', 'cook', 'fudge', 'manipulate', 'fake', 'falsify', 'cook', 'wangle', 'misrepresent', 'cook']}, {'text': '', 'type': 'Potential Entity', 'relation': '', 'attributes': []}, {'text': '', 'type': 'Potential Entity', 'relation': '', 'attributes': ['new']}]\n",
      "\n",
      "NER Table:\n",
      "[{'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': 'Apple', 'type': 'ORG'}, {'text': '', 'type': ''}, {'text': 'Tim', 'type': 'PERSON'}, {'text': 'Cook', 'type': 'PERSON'}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}, {'text': '', 'type': ''}]\n",
      "\n",
      "Dependency Parsing Table:\n",
      "[{'word': 'The', 'pos': 'DET', 'dependency': 'det', 'head': 'CEO'}, {'word': 'CEO', 'pos': 'NOUN', 'dependency': 'nsubj', 'head': 'announced'}, {'word': 'of', 'pos': 'ADP', 'dependency': 'prep', 'head': 'CEO'}, {'word': 'Apple', 'pos': 'PROPN', 'dependency': 'pobj', 'head': 'of'}, {'word': ',', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'CEO'}, {'word': 'Tim', 'pos': 'PROPN', 'dependency': 'compound', 'head': 'Cook'}, {'word': 'Cook', 'pos': 'PROPN', 'dependency': 'appos', 'head': 'CEO'}, {'word': ',', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'CEO'}, {'word': 'announced', 'pos': 'VERB', 'dependency': 'ROOT', 'head': 'announced'}, {'word': 'a', 'pos': 'DET', 'dependency': 'det', 'head': 'launch'}, {'word': 'new', 'pos': 'ADJ', 'dependency': 'amod', 'head': 'launch'}, {'word': 'product', 'pos': 'NOUN', 'dependency': 'compound', 'head': 'launch'}, {'word': 'launch', 'pos': 'NOUN', 'dependency': 'dobj', 'head': 'announced'}, {'word': '.', 'pos': 'PUNCT', 'dependency': 'punct', 'head': 'announced'}]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "def analyze_sentence(sentence):\n",
    "  \"\"\"\n",
    "  Analyzes a sentence and outputs ontology, NER, and dependency parsing data with \n",
    "  improvements for relation/attribute identification, lexical resources, coreference \n",
    "  resolution, and disambiguation.\n",
    "\n",
    "  Args:\n",
    "      sentence (str): The sentence to be analyzed.\n",
    "\n",
    "  Returns:\n",
    "      dict: A dictionary containing the ontology, NER, and dependency parsing results.\n",
    "  \"\"\"\n",
    "  doc = nlp(sentence)\n",
    "\n",
    "  # Prepare empty results dictionary\n",
    "  results = {\n",
    "      \"ontology\": [],\n",
    "      \"ner\": [],\n",
    "      \"dependency_parsing\": []\n",
    "  }\n",
    "\n",
    "  # Coreference resolution (using simple heuristic)\n",
    "  coref_chains = {}\n",
    "  for token in doc:\n",
    "    if token.dep_ == \"nsubj\":  # Identify potential subjects\n",
    "      entity_text = token.text\n",
    "      if entity_text in coref_chains:\n",
    "        coref_chains[entity_text].append(token.idx)\n",
    "      else:\n",
    "        coref_chains[entity_text] = [token.idx]\n",
    "\n",
    "  # Process each token\n",
    "  for token in doc:\n",
    "    text = token.text\n",
    "    pos = token.pos_\n",
    "    dep_ = token.dep_\n",
    "    head = token.head.text\n",
    "\n",
    "    # Named Entity Recognition (NER)\n",
    "    entity_text = \"\"\n",
    "    entity_type = \"\"\n",
    "    if token.ent_type_:\n",
    "      entity_text = text\n",
    "      entity_type = token.ent_type_\n",
    "    results[\"ner\"].append({\"text\": entity_text, \"type\": entity_type})\n",
    "\n",
    "    # Ontology Table with relation and attribute logic\n",
    "    if pos in [\"NOUN\", \"PROPN\"]:\n",
    "      relation = \"\"\n",
    "      attributes = []\n",
    "\n",
    "      # Check for verb phrase as relation (consider dependency parsing)\n",
    "      if dep_ == \"ROOT\" or dep_ == \"verb\":\n",
    "        relation = head\n",
    "\n",
    "      # Identify potential attributes using part-of-speech and dependency parsing\n",
    "      for child in token.children:\n",
    "        if child.pos_ in [\"ADJ\", \"ADP\"]:  # Adjectives or adpositional phrases\n",
    "          attributes.append(child.text)\n",
    "\n",
    "      # Coreference resolution (apply to previously identified entity)\n",
    "      if token.idx in coref_chains:\n",
    "        entity_text = coref_chains[entity_text][0]  # Use first mention as reference\n",
    "        entity_text = doc[entity_text].text\n",
    "\n",
    "      results[\"ontology\"].append({\n",
    "          \"text\": entity_text,\n",
    "          \"type\": \"Entity\" if entity_type else \"Potential Entity\",\n",
    "          \"relation\": relation,\n",
    "          \"attributes\": attributes\n",
    "      })\n",
    "\n",
    "    # Dependency Parsing\n",
    "    results[\"dependency_parsing\"].append({\n",
    "        \"word\": text,\n",
    "        \"pos\": pos,\n",
    "        \"dependency\": dep_,\n",
    "        \"head\": head\n",
    "    })\n",
    "\n",
    "  # WordNet integration (enrich ontology with hypernyms/synonyms)\n",
    "  for entity in results[\"ontology\"]:\n",
    "    if entity[\"text\"]:\n",
    "      synsets = wn.synsets(entity[\"text\"])\n",
    "      if synsets:\n",
    "        entity[\"hypernyms\"] = [synset.hypernyms() for synset in synsets][0]  # Get first hypernym\n",
    "        entity[\"synonyms\"] = [lemma.name() for synset in synsets for lemma in synset.lemmas()]\n",
    "\n",
    "  # Disambiguation (simple example using WordNet glosses)\n",
    "  for entity in results[\"ontology\"]:\n",
    "    if entity[\"relation\"] and entity[\"text\"]:\n",
    "      synsets = wn.synsets(entity[\"text\"])\n",
    "      if synsets:\n",
    "        gloss_matches = [gloss for synset in synsets for gloss in synset.definition().split() if entity[\"relation\"] in gloss]\n",
    "        if gloss_matches:\n",
    "          entity[\"relation\"] = gloss_matches[0]  # Choose first gloss match (can be improved)\n",
    "\n",
    "  return results\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The CEO of Apple, Tim Cook, announced a new product launch.\"\n",
    "analysis_result = analyze_sentence(sentence)\n",
    "\n",
    "# Print the results (further processing might be needed)\n",
    "print(\"Ontology Table:\")\n",
    "print(analysis_result[\"ontology\"])\n",
    "print(\"\\nNER Table:\")\n",
    "print(analysis_result[\"ner\"])\n",
    "print(\"\\nDependency Parsing Table:\")\n",
    "print(analysis_result[\"dependency_parsing\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': '',\n",
       "  'type': 'Potential Entity',\n",
       "  'relation': '',\n",
       "  'attributes': ['of']},\n",
       " {'text': 'Apple',\n",
       "  'type': 'Entity',\n",
       "  'relation': '',\n",
       "  'attributes': [],\n",
       "  'hypernyms': [Synset('edible_fruit.n.01'), Synset('pome.n.01')],\n",
       "  'synonyms': ['apple', 'apple', 'orchard_apple_tree', 'Malus_pumila']},\n",
       " {'text': 'Tim', 'type': 'Entity', 'relation': '', 'attributes': []},\n",
       " {'text': 'Cook',\n",
       "  'type': 'Entity',\n",
       "  'relation': '',\n",
       "  'attributes': [],\n",
       "  'hypernyms': [Synset('skilled_worker.n.01')],\n",
       "  'synonyms': ['cook',\n",
       "   'Cook',\n",
       "   'James_Cook',\n",
       "   'Captain_Cook',\n",
       "   'Captain_James_Cook',\n",
       "   'cook',\n",
       "   'cook',\n",
       "   'fix',\n",
       "   'ready',\n",
       "   'make',\n",
       "   'prepare',\n",
       "   'cook',\n",
       "   'fudge',\n",
       "   'manipulate',\n",
       "   'fake',\n",
       "   'falsify',\n",
       "   'cook',\n",
       "   'wangle',\n",
       "   'misrepresent',\n",
       "   'cook']},\n",
       " {'text': '', 'type': 'Potential Entity', 'relation': '', 'attributes': []},\n",
       " {'text': '',\n",
       "  'type': 'Potential Entity',\n",
       "  'relation': '',\n",
       "  'attributes': ['new']}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_result[\"ontology\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
